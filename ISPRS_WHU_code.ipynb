{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FjfKxz-hief"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from torch import Tensor\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as cp\n",
        "from collections import OrderedDict\n",
        "from torch import Tensor\n",
        "from typing import Type, Any, Callable, Union, List, Optional\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import Subset,DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "import random\n",
        "from google.colab import files\n",
        "from sklearn.metrics import  confusion_matrix\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "from torch.autograd import Variable\n",
        "import skimage.segmentation\n",
        "import skimage.io\n",
        "import skimage\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import skimage.segmentation\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "import skimage.segmentation\n",
        "from skimage import feature\n",
        "from skimage import filters\n",
        "import copy\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def randomHueSaturationValue(\n",
        "    image,\n",
        "    hue_shift_limit=(-40, 40),\n",
        "    sat_shift_limit=(-10, 10),\n",
        "    val_shift_limit=(-20, 20),\n",
        "    u=0.5,\n",
        "):\n",
        "    if np.random.random() < u:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        h, s, v = cv2.split(image)\n",
        "        hue_shift = np.random.randint(\n",
        "            hue_shift_limit[0], hue_shift_limit[1] + 1)\n",
        "        hue_shift = np.uint8(hue_shift)\n",
        "        h += hue_shift\n",
        "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
        "        s = cv2.add(s, sat_shift)\n",
        "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
        "        v = cv2.add(v, val_shift)\n",
        "        image = cv2.merge((h, s, v))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_HSV2BGR)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def randomShiftScaleRotate(\n",
        "    image,\n",
        "    mask,\n",
        "    shift_limit=(-0.1, 0.1),\n",
        "    scale_limit=(-0.1, 0.1),\n",
        "    aspect_limit=(-0.1, 0.1),\n",
        "    rotate_limit=(-0, 0),\n",
        "    borderMode=cv2.BORDER_CONSTANT,\n",
        "    u=0.5,\n",
        "):\n",
        "    if np.random.random() < u:\n",
        "        height, width, channel = image.shape\n",
        "\n",
        "        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])\n",
        "        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
        "        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
        "        sx = scale * aspect / (aspect ** 0.5)\n",
        "        sy = scale / (aspect ** 0.5)\n",
        "        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
        "        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
        "\n",
        "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
        "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
        "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
        "\n",
        "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height]])\n",
        "        box1 = box0 - np.array([width / 2, height / 2])\n",
        "        box1 = np.dot(box1, rotate_matrix.T) + np.array(\n",
        "            [width / 2 + dx, height / 2 + dy]\n",
        "        )\n",
        "\n",
        "        box0 = box0.astype(np.float32)\n",
        "        box1 = box1.astype(np.float32)\n",
        "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
        "        image = cv2.warpPerspective(\n",
        "            image,\n",
        "            mat,\n",
        "            (width, height),\n",
        "            flags=cv2.INTER_NEAREST,\n",
        "            borderMode=borderMode,\n",
        "            borderValue=(0, 0, 0),\n",
        "        )\n",
        "        mask = cv2.warpPerspective(\n",
        "            mask,\n",
        "            mat,\n",
        "            (width, height),\n",
        "            flags=cv2.INTER_NEAREST,\n",
        "            borderMode=borderMode,\n",
        "            borderValue=(0, 0, 0),\n",
        "        )\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def randomHorizontalFlip(image, mask, u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        image = cv2.flip(image, 1)\n",
        "        mask = cv2.flip(mask, 1)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def randomVerticleFlip(image, mask, u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        image = cv2.flip(image, 0)\n",
        "        mask = cv2.flip(mask, 0)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def randomRotate90(image, mask, u=0.5):\n",
        "    if np.random.random() < u:\n",
        "        image = np.rot90(image)\n",
        "        mask = np.rot90(mask)\n",
        "\n",
        "    return image, mask"
      ],
      "metadata": {
        "id": "iEYhVdFWDIuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patches_2d(img,patch_shape,step=[1.0,1.0],batch_first=False):\n",
        "    patch_H, patch_W = patch_shape[0], patch_shape[1]\n",
        "    if(img.size(2)<patch_H):\n",
        "        num_padded_H_Top = (patch_H - img.size(2))//2\n",
        "        num_padded_H_Bottom = patch_H - img.size(2) - num_padded_H_Top\n",
        "        padding_H = nn.ConstantPad2d((0,0,num_padded_H_Top,num_padded_H_Bottom),0)\n",
        "        img = padding_H(img)\n",
        "    if(img.size(3)<patch_W):\n",
        "        num_padded_W_Left = (patch_W - img.size(3))//2\n",
        "        num_padded_W_Right = patch_W - img.size(3) - num_padded_W_Left\n",
        "        padding_W = nn.ConstantPad2d((num_padded_W_Left,num_padded_W_Right,0,0),0)\n",
        "        img = padding_W(img)\n",
        "    step_int = [0,0]\n",
        "    step_int[0] = int(patch_H*step[0]) if(isinstance(step[0], float)) else step[0]\n",
        "    step_int[1] = int(patch_W*step[1]) if(isinstance(step[1], float)) else step[1]\n",
        "    patches_fold_H = img.unfold(2, patch_H, step_int[0])\n",
        "    if((img.size(2) - patch_H) % step_int[0] != 0):\n",
        "        patches_fold_H = torch.cat((patches_fold_H,img[:,:,-patch_H:,].permute(0,1,3,2).unsqueeze(2)),dim=2)\n",
        "    patches_fold_HW = patches_fold_H.unfold(3, patch_W, step_int[1])\n",
        "    if((img.size(3) - patch_W) % step_int[1] != 0):\n",
        "        patches_fold_HW = torch.cat((patches_fold_HW,patches_fold_H[:,:,:,-patch_W:,:].permute(0,1,2,4,3).unsqueeze(3)),dim=3)\n",
        "    patches = patches_fold_HW.permute(2,3,0,1,4,5)\n",
        "    patches = patches.reshape(-1,img.size(0),img.size(1),patch_H,patch_W)\n",
        "    if(batch_first):\n",
        "        patches = patches.permute(1,0,2,3,4)\n",
        "    return patches\n",
        "\n",
        "def reconstruct_from_patches_2d(patches,img_shape,step=[1.0,1.0],batch_first=False):\n",
        "    if(batch_first):\n",
        "        patches = patches.permute(1,0,2,3,4)\n",
        "    patch_H, patch_W = patches.size(3), patches.size(4)\n",
        "    img_size = (patches.size(1), patches.size(2),max(img_shape[0], patch_H), max(img_shape[1], patch_W))\n",
        "    step_int = [0,0]\n",
        "    step_int[0] = int(patch_H*step[0]) if(isinstance(step[0], float)) else step[0]\n",
        "    step_int[1] = int(patch_W*step[1]) if(isinstance(step[1], float)) else step[1]\n",
        "    nrow, ncol = 1 + (img_size[-2] - patch_H)//step_int[0], 1 + (img_size[-1] - patch_W)//step_int[1]\n",
        "    r_nrow = nrow + 1 if((img_size[2] - patch_H) % step_int[0] != 0) else nrow\n",
        "    r_ncol = ncol + 1 if((img_size[3] - patch_W) % step_int[1] != 0) else ncol\n",
        "    patches = patches.reshape(r_nrow,r_ncol,img_size[0],img_size[1],patch_H,patch_W)\n",
        "    img = torch.zeros(img_size, device = patches.device)\n",
        "    overlap_counter = torch.zeros(img_size, device = patches.device)\n",
        "    for i in range(nrow):\n",
        "        for j in range(ncol):\n",
        "            img[:,:,i*step_int[0]:i*step_int[0]+patch_H,j*step_int[1]:j*step_int[1]+patch_W] += patches[i,j,]\n",
        "            overlap_counter[:,:,i*step_int[0]:i*step_int[0]+patch_H,j*step_int[1]:j*step_int[1]+patch_W] += 1\n",
        "    if((img_size[2] - patch_H) % step_int[0] != 0):\n",
        "        for j in range(ncol):\n",
        "            img[:,:,-patch_H:,j*step_int[1]:j*step_int[1]+patch_W] += patches[-1,j,]\n",
        "            overlap_counter[:,:,-patch_H:,j*step_int[1]:j*step_int[1]+patch_W] += 1\n",
        "    if((img_size[3] - patch_W) % step_int[1] != 0):\n",
        "        for i in range(nrow):\n",
        "            img[:,:,i*step_int[0]:i*step_int[0]+patch_H,-patch_W:] += patches[i,-1,]\n",
        "            overlap_counter[:,:,i*step_int[0]:i*step_int[0]+patch_H,-patch_W:] += 1\n",
        "    if((img_size[2] - patch_H) % step_int[0] != 0 and (img_size[3] - patch_W) % step_int[1] != 0):\n",
        "        img[:,:,-patch_H:,-patch_W:] += patches[-1,-1,]\n",
        "        overlap_counter[:,:,-patch_H:,-patch_W:] += 1\n",
        "    img /= overlap_counter\n",
        "    if(img_shape[0]<patch_H):\n",
        "        num_padded_H_Top = (patch_H - img_shape[0])//2\n",
        "        num_padded_H_Bottom = patch_H - img_shape[0] - num_padded_H_Top\n",
        "        img = img[:,:,num_padded_H_Top:-num_padded_H_Bottom,]\n",
        "    if(img_shape[1]<patch_W):\n",
        "        num_padded_W_Left = (patch_W - img_shape[1])//2\n",
        "        num_padded_W_Right = patch_W - img_shape[1] - num_padded_W_Left\n",
        "        img = img[:,:,:,num_padded_W_Left:-num_padded_W_Right]\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "2rb8g5M5DMZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_train=glob.glob('/content/drive/MyDrive/3. The cropped image tiles and raster labels/train/image*/**.tif')\n",
        "image_path_train.sort()\n",
        "label_path_train=glob.glob('/content/drive/MyDrive/3. The cropped image tiles and raster labels/train/label*/**.tif')\n",
        "label_path_train.sort()"
      ],
      "metadata": {
        "id": "cyAQCGJCDPN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_val=glob.glob('/content/drive/MyDrive/3. The cropped image tiles and raster labels/val/image*/**.tif')\n",
        "image_path_val.sort()\n",
        "label_path_val=glob.glob('/content/drive/MyDrive/3. The cropped image tiles and raster labels/val/label*/**.tif')\n",
        "label_path_val.sort()"
      ],
      "metadata": {
        "id": "BL5HCHYBVxiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path_test1=glob.glob('/content/drive/MyDrive/3. The cropped image tiles and raster labels/test/image*/**.tif')\n",
        "image_path_test1.sort()\n",
        "image_path_test=image_path_test1[1:301]\n",
        "\n",
        "label_path_test1=glob.glob('/content/drive/MyDrive/3. The cropped image tiles and raster labels/test/label*/**.tif')\n",
        "label_path_test1.sort()\n",
        "label_path_test=label_path_test1[1:301]\n"
      ],
      "metadata": {
        "id": "qf5pV4XFeYjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, target_paths):\n",
        "\n",
        "        self.image_paths = image_paths\n",
        "        self.target_paths = target_paths\n",
        "        self.transforms = transforms.ToTensor()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        image = cv2.imread(self.image_paths[index])\n",
        "        mask = cv2.imread(self.target_paths[index])\n",
        "        image = self.transforms(image[:,:,:])\n",
        "        mask = self.transforms(mask[:,:,0:1])\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "\n",
        "train_dataset = CustomDataset(image_path_train, label_path_train)\n",
        "train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "val_dataset = CustomDataset(image_path_val, label_path_val)\n",
        "val_dl = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "test_dataset = CustomDataset(image_path_test, label_path_test)\n",
        "test_dl = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "print(len(train_dataset))\n",
        "print(len(val_dataset))\n",
        "print(len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LumD2McN8QnY",
        "outputId": "611616b7-8279-4da4-8423-64a1f8c31b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4736\n",
            "1036\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n"
      ],
      "metadata": {
        "id": "swMTzCKon1r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Upsample(nn.Module):\n",
        "    \"\"\" nn.Upsample is deprecated \"\"\"\n",
        "\n",
        "    def __init__(self, scale_factor, mode=\"bilinear\"):\n",
        "        super(Upsample, self).__init__()\n",
        "        self.scale_factor = scale_factor\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode, align_corners=True, recompute_scale_factor=True)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1cdnQIyFn6_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index Pooling\n",
        "class pool(nn.Module):\n",
        "  def __init__(self,channels):\n",
        "    super(pool, self).__init__()\n",
        "    self.channels=channels\n",
        "    self.weight1 = torch.zeros((channels,1,2,2)).cuda()\n",
        "    self.weight2 = torch.zeros((channels,1,2,2)).cuda()\n",
        "    self.weight3 = torch.zeros((channels,1,2,2)).cuda()\n",
        "    self.weight4 = torch.zeros((channels,1,2,2)).cuda()\n",
        "    self.weight1[:,:,0,0]=1\n",
        "    self.weight2[:,:,0,1]=1\n",
        "    self.weight3[:,:,1,0]=1\n",
        "    self.weight4[:,:,1,1]=1\n",
        "  def forward(self, x):\n",
        "    with torch.no_grad():\n",
        "         x1=F.conv2d(x, self.weight1,stride=2,groups=self.channels, bias=None)\n",
        "         x2=F.conv2d(x, self.weight2,stride=2,groups=self.channels, bias=None)\n",
        "         x3=F.conv2d(x, self.weight3,stride=2,groups=self.channels, bias=None)\n",
        "         x4=F.conv2d(x, self.weight4,stride=2,groups=self.channels, bias=None)\n",
        "    return x1,x2,x3,x4"
      ],
      "metadata": {
        "id": "bPoVVPx3n86z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DAMIP Module\n",
        "class attn_pool(nn.Module):\n",
        "    def __init__(self,feature_channels):\n",
        "       super(attn_pool, self).__init__()\n",
        "       self.pool1=pool(feature_channels)\n",
        "       self.pool2=pool(1)\n",
        "       self.conv1 = nn.Conv2d(feature_channels*4, 2*feature_channels, kernel_size=1, stride=1, bias=False)\n",
        "       self.conv2 = nn.Conv2d(2*feature_channels,2*feature_channels,kernel_size=7,stride=1,padding=3)\n",
        "       self.bn2 = nn.BatchNorm2d(2*feature_channels)\n",
        "       self.a1=nn.Parameter(torch.Tensor(1))\n",
        "       self.a2=nn.Parameter(torch.Tensor(1))\n",
        "       self.a3=nn.Parameter(torch.Tensor(1))\n",
        "       self.a4=nn.Parameter(torch.Tensor(1))\n",
        "    def forward(self,map,feature):\n",
        "        feature1,feature2,feature3,feature4=self.pool1(feature)\n",
        "        map1,map2,map3,map4=self.pool2(map)\n",
        "\n",
        "        fm1 = self.a1*feature1 + feature1*map1\n",
        "        fm2 = self.a2*feature2 + feature2*map2\n",
        "        fm3 = self.a3*feature3 + feature3*map3\n",
        "        fm4 = self.a4*feature4 + feature4*map4\n",
        "\n",
        "        mat=torch.cat((fm1,fm2,fm3,fm4),1)\n",
        "        mat=self.conv1(mat)\n",
        "        mat=F.relu(self.bn2(self.conv2(mat)))\n",
        "        return mat"
      ],
      "metadata": {
        "id": "A3uMEefen-8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DPMG Module\n",
        "class dsup(nn.Module):\n",
        "  def __init__(self,input_channels):\n",
        "    super(dsup,self).__init__()\n",
        "    self.conv1=conv3x3(input_channels,input_channels//2)\n",
        "    self.bn1=nn.BatchNorm2d(input_channels//2)\n",
        "    self.conv2=conv3x3(input_channels//2,32)\n",
        "    self.conv3=nn.Conv2d(32,1,kernel_size=3,stride=1,padding=1)\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.bn1(self.conv1(x)))\n",
        "    x=self.conv2(x)\n",
        "    x=self.conv3(x)\n",
        "    return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "y0d1HSMVoBDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dilated Convolutional Block\n",
        "class conv_enc(nn.Module):\n",
        "  def __init__(self,in_channels,out_channels,dil):\n",
        "    super(conv_enc,self).__init__()\n",
        "    self.conv1 = conv1x1(in_channels,in_channels)\n",
        "    self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "    self.conv2 = conv3x3(in_channels,in_channels,dilation=dil)\n",
        "    self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "    self.conv3 = conv1x1(in_channels,out_channels)\n",
        "    self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "    self.conv4 = conv3x3(out_channels,out_channels,dilation=dil)\n",
        "    self.bn4 = nn.BatchNorm2d(out_channels)\n",
        "    # input dimension matching\n",
        "    self.conv0 = conv1x1(in_channels,out_channels)\n",
        "  def forward(self,x):\n",
        "    identity = self.conv0(x)\n",
        "\n",
        "    x=F.relu(self.bn1(self.conv1(x)))\n",
        "    x=F.relu(self.bn2(self.conv2(x)))\n",
        "    x=F.relu(self.bn3(self.conv3(x)))\n",
        "    x=self.bn4(self.conv4(x))\n",
        "\n",
        "    return F.relu(x+identity)"
      ],
      "metadata": {
        "id": "QanFkR1zoDRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class enc(nn.Module):\n",
        "  def __init__(self,input_channels,output_channels,dil):\n",
        "    super(enc,self).__init__()\n",
        "    self.conv1 = conv_enc(input_channels,output_channels,dil)\n",
        "    self.conv2 = conv_enc(output_channels,output_channels,2*dil)\n",
        "    self.dp_sup = dsup(output_channels)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x1 = self.conv1(x)\n",
        "    x1 = self.conv2(x1)\n",
        "    x1_out = self.dp_sup(x1)\n",
        "    return x1, x1_out"
      ],
      "metadata": {
        "id": "tVgYZiDOoFe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DAMSCA Module\n",
        "class kqcbam(nn.Module):\n",
        "  def __init__(self,input_channels,scale_factor=2):\n",
        "    super(kqcbam,self).__init__()\n",
        "    self.conv1=nn.Conv2d(1,input_channels,kernel_size=1)\n",
        "    self.gap=nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.upsample=Upsample(scale_factor)\n",
        "  def forward(self,map,feature):\n",
        "    f1=map*feature\n",
        "    map2=self.conv1(map)\n",
        "    map2=self.gap(map2)\n",
        "    f2=torch.sigmoid(map2)*feature\n",
        "    out=F.relu(f1+f2)\n",
        "    return self.upsample(out)"
      ],
      "metadata": {
        "id": "-Dvfnz4LoHXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder Module\n",
        "class decoder(nn.Module):\n",
        "  def __init__(self,input_channels):\n",
        "    super(decoder,self).__init__()\n",
        "    self.conv1=nn.ConvTranspose2d(input_channels,128,kernel_size=4,stride=2,padding=1)\n",
        "    self.bn1=nn.BatchNorm2d(128)\n",
        "    self.conv2=nn.Conv2d(128,64,3,stride=1,padding=1)\n",
        "    self.bn2=nn.BatchNorm2d(64)\n",
        "    self.conv3=nn.Conv2d(64,32,3,stride=1,padding=1)\n",
        "    self.conv_out=nn.Conv2d(32,1,3,stride=1,padding=1)\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.bn1(self.conv1(x)))\n",
        "    x=F.relu(self.bn2(self.conv2(x)))\n",
        "    x=self.conv3(x)\n",
        "    x=self.conv_out(x)\n",
        "    return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "CftgcKB_oJSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MSSDMPA-Net\n",
        "class dsmpnet(nn.Module):\n",
        "  def __init__(self,input_channels):\n",
        "    super(dsmpnet,self).__init__()\n",
        "    self.conv1=nn.Conv2d(input_channels,64,kernel_size=7,stride=2,padding=3)\n",
        "    self.bn1=nn.BatchNorm2d(64)\n",
        "\n",
        "    self.pool1=attn_pool(64)\n",
        "    self.pool2=attn_pool(128)\n",
        "    self.pool3=attn_pool(256)\n",
        "\n",
        "    self.path1=enc(64,64,1)\n",
        "    self.path2=enc(128,128,2)\n",
        "    self.path3=enc(256,256,3)\n",
        "    self.path4=enc(512,512,4)\n",
        "\n",
        "    self.cbm1=kqcbam(64,1)\n",
        "    self.cbm2=kqcbam(128,2)\n",
        "    self.cbm3=kqcbam(256,4)\n",
        "    self.cbm4=kqcbam(512,8)\n",
        "\n",
        "    self.decoder=decoder(960)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=F.relu(self.bn1(self.conv1(x)))\n",
        "    x1,x1_out=self.path1(x)\n",
        "    x=self.pool1(x1_out,x)\n",
        "    x2,x2_out=self.path2(x)\n",
        "    x=self.pool2(x2_out,x)\n",
        "    x3,x3_out=self.path3(x)\n",
        "    x=self.pool3(x3_out,x)\n",
        "    x4,x4_out=self.path4(x)\n",
        "\n",
        "    x1=self.cbm1(x1_out,x1)\n",
        "    x2=self.cbm2(x2_out,x2)\n",
        "    x3=self.cbm3(x3_out,x3)\n",
        "    x4=self.cbm4(x4_out,x4)\n",
        "    x_out=torch.cat((x1,x2,x3,x4),1)\n",
        "    x_out=self.decoder(x_out)\n",
        "    return x_out,x1_out,x2_out,x3_out,x4_out\n"
      ],
      "metadata": {
        "id": "kGwSW7JMoMCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=dsmpnet(3).cuda()\n",
        "model=model.to('cuda:0')"
      ],
      "metadata": {
        "id": "lA2K6Ocz-Hg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class gen_loss(nn.Module):\n",
        "  def __init__(self,gamma=1.5,batch=True):\n",
        "    super(gen_loss,self).__init__()\n",
        "    self.bce_loss=nn.BCELoss()\n",
        "    self.gamma=gamma\n",
        "\n",
        "  def gen_dice(self,y_pred,y_true):\n",
        "    epsilon=1e-8\n",
        "    l1=abs(y_pred-y_true)**self.gamma\n",
        "    y_pred_sqsum=torch.sum((y_pred*y_pred))\n",
        "    y_true_sqsum=torch.sum((y_true*y_true))\n",
        "    l1_sum=torch.sum(l1)\n",
        "    score=(l1_sum + epsilon)/(y_pred_sqsum + y_true_sqsum )\n",
        "    return score.mean()\n",
        "\n",
        "  def __call__(self,y_pred,y_true):\n",
        "    a=self.bce_loss(y_pred,y_true)\n",
        "    b=self.gen_dice(y_pred,y_true)\n",
        "    return a+b"
      ],
      "metadata": {
        "id": "A0iXMYDb97_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def y_bce_loss(prediction1,prediction2,prediction3,prediction4,prediction5,label):\n",
        "    dice=gen_loss()\n",
        "    loss1=dice(prediction1,label)\n",
        "    label=torch.nn.functional.interpolate(label, size=(256,256), scale_factor=None, mode='nearest')\n",
        "    loss2=dice(prediction2,label)\n",
        "    label=torch.nn.functional.interpolate(label, size=(128,128), scale_factor=None, mode='nearest')\n",
        "    loss3=dice(prediction3,label)\n",
        "    label=torch.nn.functional.interpolate(label, size=(64,64), scale_factor=None, mode='nearest')\n",
        "    loss4=dice(prediction4,label)\n",
        "    label=torch.nn.functional.interpolate(label, size=(32,32), scale_factor=None, mode='nearest')\n",
        "    loss5=dice(prediction5,label)\n",
        "    loss=loss1+loss2+loss3+loss4+loss5\n",
        "    return loss"
      ],
      "metadata": {
        "id": "oiHjVKOr-H4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IoU(nn.Module):\n",
        "    def __init__(self, threshold=0.5):\n",
        "        super(IoU, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def forward(self, target, input):\n",
        "        eps = 1e-10\n",
        "        input_ = (input > self.threshold).data.float()\n",
        "        target_ = (target > self.threshold).data.float()\n",
        "\n",
        "        intersection = torch.clamp(input_ * target_, 0, 1)\n",
        "        union = torch.clamp(input_ + target_, 0, 1)\n",
        "\n",
        "        if torch.mean(intersection).lt(eps):\n",
        "            return torch.Tensor([0., 0., 0., 0.])\n",
        "        else:\n",
        "            acc = torch.mean((input_ == target_).data.float())\n",
        "            iou = torch.mean(intersection) / torch.mean(union)\n",
        "            recall = torch.mean(intersection) / torch.mean(target_)\n",
        "            precision = torch.mean(intersection) / torch.mean(input_)\n",
        "            return torch.Tensor([acc, recall, precision, iou])\n",
        "iou=IoU()"
      ],
      "metadata": {
        "id": "jTJBPaLX-Pfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coeff(y_true,y_pred,batch=True):\n",
        "        smooth = 1e-8\n",
        "        if batch:\n",
        "            i = torch.sum(y_true)\n",
        "            j = torch.sum(y_pred)\n",
        "            intersection = torch.sum(y_true * y_pred)\n",
        "        else:\n",
        "            i = y_true.sum(1).sum(1).sum(1)\n",
        "            j = y_pred.sum(1).sum(1).sum(1)\n",
        "            intersection = (y_true * y_pred).sum(1).sum(1).sum(1)\n",
        "        score = (2. * intersection + smooth) / (i + j + smooth)\n",
        "        return score.mean()\n"
      ],
      "metadata": {
        "id": "g6Z4k8Sh-SY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch_net(model, train_dl, learn):\n",
        "    opt = torch.optim.Adam(model.parameters(),lr=learn)\n",
        "    running_loss_image=0.0\n",
        "    metric_epoch=0.0\n",
        "    dice_epoch=0.0\n",
        "    for a,b in train_dl:\n",
        "        a=a.float()\n",
        "        label=b.float()\n",
        "        label_loss=b.type(torch.float)\n",
        "        pred1,pred2,pred3,pred4,pred5=model(a.cuda())\n",
        "        loss=y_bce_loss(pred1,pred2,pred3,pred4,pred5,label_loss.cuda())\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        running_loss_image += loss\n",
        "        metric=iou(label_loss,pred1.detach().cpu())\n",
        "        dice = dice_coeff(label_loss,pred1.detach().cpu())\n",
        "        dice_epoch += dice\n",
        "        metric_epoch += metric\n",
        "    running_loss_image/=len(train_dl)\n",
        "    metric_epoch /= len(train_dl)\n",
        "    dice_epoch /= len(train_dl)\n",
        "    return model, dice_epoch, metric_epoch, running_loss_image\n",
        "\n",
        "def validate_one_epoch_net(model, val_dl):\n",
        "    running_loss_image=0.0\n",
        "    metric_epoch=0.0\n",
        "    dice_epoch=0.0\n",
        "    with torch.no_grad():\n",
        "        for a,b in val_dl:\n",
        "            a=a.float()\n",
        "            label=b.float()\n",
        "            label_loss=b.type(torch.float)\n",
        "            pred1,pred2,pred3,pred4,pred5=model(a.cuda())\n",
        "            loss=y_bce_loss(pred1,pred2,pred3,pred4,pred5,label_loss.cuda())\n",
        "            running_loss_image += loss\n",
        "            metric=iou(label_loss,pred1.detach().cpu())\n",
        "            dice = dice_coeff(label_loss,pred1.detach().cpu())\n",
        "            dice_epoch += dice\n",
        "            metric_epoch += metric\n",
        "    running_loss_image/=len(val_dl)\n",
        "    metric_epoch /= len(val_dl)\n",
        "    dice_epoch /= len(val_dl)\n",
        "    return dice_epoch, metric_epoch, running_loss_image\n"
      ],
      "metadata": {
        "id": "z7Gn_4zA-UQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoches_net(model,train_dl,test_dl,epoches,learn,path):\n",
        "    max_accuracy=0.0\n",
        "    for i in range(epoches):\n",
        "        model, dice_train, iou_train, loss_train=train_one_epoch_net(model,train_dl,learn)\n",
        "        dice_test, iou_test, loss_test=validate_one_epoch_net(model,test_dl)\n",
        "        print('epoch finished' +\" \" + str(i+1))\n",
        "        print(f'train_loss: {loss_train:.6f}, train_dice: {dice_train:.6f}, train_iou: {iou_train[3]:.6f}')\n",
        "        print(f'test_loss: {loss_test:.6f}, test_dice: {dice_test:.6f}, test_iou: {iou_test[3]:.6f}')\n",
        "        path_final=os.path.join(path,\n",
        "                                    f\"epoch{i}_test_loss{loss_test:.4f}.pth\")\n",
        "        torch.save(model.state_dict(), path_final)"
      ],
      "metadata": {
        "id": "SIuQR6ev-ZLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir tgrs1\n",
        "train_epoches_net(model,test_dl,test_dl,20,0.00001,'/content/tgrs1')\n"
      ],
      "metadata": {
        "id": "iHVViHdI-bVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/weights/building_big/tgrs_new/epoch4_test_iou0.6948'))"
      ],
      "metadata": {
        "id": "5stW3cgyNl1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3866547-0a18-44f5-f880-e2c648f8b832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl=DataLoader(test_dataset,batch_size=8,num_workers=2)\n",
        "x,y,z=validate_one_epoch_net(model,test_dl)\n",
        "print(x,y,z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn85-FFdcuJM",
        "outputId": "1d8c13e1-7ca5-452f-ac10-39e9ec4af625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7974) tensor([0.9830, 0.7974, 0.8574, 0.7000]) tensor(1.3297, device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}